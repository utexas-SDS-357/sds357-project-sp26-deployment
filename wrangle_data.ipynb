{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "1991c1a8",
      "metadata": {},
      "source": [
        "# Get required packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "19a522c9",
      "metadata": {},
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b5182de",
      "metadata": {},
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a27677a0",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pyogrio"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5633f2cd",
      "metadata": {},
      "source": [
        "# Read data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88bdee15",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "         date service_area  search_conducted\n",
            "0  2014-01-01          110             False\n",
            "1  2014-01-01          320             False\n",
            "2  2014-01-01          320             False\n",
            "3  2014-01-01          610             False\n",
            "4  2014-01-01          930             False\n",
            "         FIPS  RPL_THEMES\n",
            "0  6001400100      0.1598\n",
            "1  6001400200      0.1827\n",
            "2  6001400300      0.2366\n",
            "3  6001400400      0.1451\n",
            "4  6001400500      0.2148\n"
          ]
        }
      ],
      "source": [
        "sopp = pd.read_csv('data/ca_san_diego_2020_04_01.csv')\n",
        "svi_tab = pd.read_csv('data/California.csv')\n",
        "\n",
        "# These are the columns for merging later\n",
        "svi_tab = svi_tab[['FIPS', 'RPL_THEMES']].copy()\n",
        "svi_tab['FIPS'] = svi_tab['FIPS'].astype(str).str.replace(r'\\.0$', '', regex=True) # chat regex\n",
        "\n",
        "print(sopp[['date','service_area','search_conducted']].head())\n",
        "print(svi_tab.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e31ff0a2",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   objectid  beat  div  serv        name  \\\n",
            "0         9   935    9   930  NORTH CITY   \n",
            "1        13     0    0     0   SAN DIEGO   \n",
            "2        14   511    5   510         NaN   \n",
            "3        15   722    7   720      NESTOR   \n",
            "4        16   314    3   310    BIRDLAND   \n",
            "\n",
            "                                            geometry  \n",
            "0  POLYGON ((-117.23876 32.98575, -117.2387 32.98...  \n",
            "1  MULTIPOLYGON (((-117.22526 32.70267, -117.2252...  \n",
            "2  MULTIPOLYGON (((-117.22529 32.7026, -117.22525...  \n",
            "3  POLYGON ((-117.09042 32.58382, -117.09001 32.5...  \n",
            "4  POLYGON ((-117.15149 32.8065, -117.1514 32.806...  \n",
            "['objectid', 'beat', 'div', 'serv', 'name', 'geometry']\n",
            "EPSG:4326\n"
          ]
        }
      ],
      "source": [
        "# Shape files for tract SVI data and police service zones\n",
        "cdc_gdb_path = \"/Users/asmit/Downloads/SVI2014_CALIFORNIA_tract.gdb/\"\n",
        "beats_path = \"./data/Police_Beats.geojson\"\n",
        "\n",
        "# Some info about the police service zones\n",
        "# Contains meta data + spatial geometry\n",
        "beats = gpd.read_file(beats_path)\n",
        "print(beats.head())\n",
        "print(beats.columns.tolist())\n",
        "print(beats.crs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9394835",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[['CALIFORNIA_tract' 'MultiPolygon Z']]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/asmit/Documents/SDS357/venv/lib/python3.13/site-packages/pyogrio/core.py:129: UserWarning: Measured (M) geometry types are not supported. Original type 'Measured 3D MultiPolygon' is converted to 'MultiPolygon Z'\n",
            "  return ogr_list_layers(get_vsi_path_or_buffer(path_or_buffer))\n"
          ]
        }
      ],
      "source": [
        "# This is just to see which part of the SVI folder has the data\n",
        "print(pyogrio.list_layers(cdc_gdb_path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed7a797f",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/asmit/Documents/SDS357/venv/lib/python3.13/site-packages/pyogrio/raw.py:200: UserWarning: Measured (M) geometry types are not supported. Original type 'Measured 3D MultiPolygon' is converted to 'MultiPolygon Z'\n",
            "  return ogr_read(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "               AFFGEOID TRACTCE  ST        STATE ST_ABBR STCNTY    COUNTY  \\\n",
            "0  1400000US06001400100  400100  06   California      CA  06001   Alameda   \n",
            "1  1400000US06001400200  400200  06   California      CA  06001   Alameda   \n",
            "2  1400000US06001400300  400300  06   California      CA  06001   Alameda   \n",
            "3  1400000US06001400400  400400  06   California      CA  06001   Alameda   \n",
            "4  1400000US06001400500  400500  06   California      CA  06001   Alameda   \n",
            "\n",
            "          FIPS                                       LOCATION  AREA_SQMI  ...  \\\n",
            "0  06001400100  Census Tract 4001, Alameda County, California   2.661917  ...   \n",
            "1  06001400200  Census Tract 4002, Alameda County, California   0.226817  ...   \n",
            "2  06001400300  Census Tract 4003, Alameda County, California   0.426770  ...   \n",
            "3  06001400400  Census Tract 4004, Alameda County, California   0.275958  ...   \n",
            "4  06001400500  Census Tract 4005, Alameda County, California   0.227919  ...   \n",
            "\n",
            "   F_THEME4  F_TOTAL  E_UNINSUR  M_UNINSUR  EP_UNINSUR  MP_UNINSUR  E_DAYPOP  \\\n",
            "0       1.0      1.0      114.0       63.0         3.4         1.9    5042.0   \n",
            "1       1.0      2.0      105.0       45.0         5.4         2.2    3190.0   \n",
            "2       0.0      0.0      404.0      203.0         7.4         3.8    4381.0   \n",
            "3       0.0      0.0      292.0      100.0         6.8         2.3    2405.0   \n",
            "4       0.0      0.0      555.0      251.0        15.8         6.6    2043.0   \n",
            "\n",
            "   Shape_Length  Shape_Area                                           geometry  \n",
            "0      0.133562    0.000707  MULTIPOLYGON Z (((-122.24692 37.88544 0, -122....  \n",
            "1      0.041215    0.000059  MULTIPOLYGON Z (((-122.25742 37.8431 0, -122.2...  \n",
            "2      0.055769    0.000113  MULTIPOLYGON Z (((-122.26416 37.84 0, -122.261...  \n",
            "3      0.035950    0.000074  MULTIPOLYGON Z (((-122.2618 37.84179 0, -122.2...  \n",
            "4      0.032189    0.000060  MULTIPOLYGON Z (((-122.26941 37.84811 0, -122....  \n",
            "\n",
            "[5 rows x 129 columns]\n",
            "['AFFGEOID', 'TRACTCE', 'ST', 'STATE', 'ST_ABBR', 'STCNTY', 'COUNTY', 'FIPS', 'LOCATION', 'AREA_SQMI', 'E_TOTPOP', 'M_TOTPOP', 'E_HU', 'M_HU', 'E_HH', 'M_HH', 'E_POV', 'M_POV', 'E_UNEMP', 'M_UNEMP', 'E_PCI', 'M_PCI', 'E_NOHSDP', 'M_NOHSDP', 'E_AGE65', 'M_AGE65', 'E_AGE17', 'M_AGE17', 'E_DISABL', 'M_DISABL', 'E_SNGPNT', 'M_SNGPNT', 'E_MINRTY', 'M_MINRTY', 'E_LIMENG', 'M_LIMENG', 'E_MUNIT', 'M_MUNIT', 'E_MOBILE', 'M_MOBILE', 'E_CROWD', 'M_CROWD', 'E_NOVEH', 'M_NOVEH', 'E_GROUPQ', 'M_GROUPQ', 'EP_POV', 'MP_POV', 'EP_UNEMP', 'MP_UNEMP', 'EP_PCI', 'MP_PCI', 'EP_NOHSDP', 'MP_NOHSDP', 'EP_AGE65', 'MP_AGE65', 'EP_AGE17', 'MP_AGE17', 'EP_DISABL', 'MP_DISABL', 'EP_SNGPNT', 'MP_SNGPNT', 'EP_MINRTY', 'MP_MINRTY', 'EP_LIMENG', 'MP_LIMENG', 'EP_MUNIT', 'MP_MUNIT', 'EP_MOBILE', 'MP_MOBILE', 'EP_CROWD', 'MP_CROWD', 'EP_NOVEH', 'MP_NOVEH', 'EP_GROUPQ', 'MP_GROUPQ', 'EPL_POV', 'EPL_UNEMP', 'EPL_PCI', 'EPL_NOHSDP', 'SPL_THEME1', 'RPL_THEME1', 'EPL_AGE65', 'EPL_AGE17', 'EPL_DISABL', 'EPL_SNGPNT', 'SPL_THEME2', 'RPL_THEME2', 'EPL_MINRTY', 'EPL_LIMENG', 'SPL_THEME3', 'RPL_THEME3', 'EPL_MUNIT', 'EPL_MOBILE', 'EPL_CROWD', 'EPL_NOVEH', 'EPL_GROUPQ', 'SPL_THEME4', 'RPL_THEME4', 'SPL_THEMES', 'RPL_THEMES', 'F_POV', 'F_UNEMP', 'F_PCI', 'F_NOHSDP', 'F_THEME1', 'F_AGE65', 'F_AGE17', 'F_DISABL', 'F_SNGPNT', 'F_THEME2', 'F_MINRTY', 'F_LIMENG', 'F_THEME3', 'F_MUNIT', 'F_MOBILE', 'F_CROWD', 'F_NOVEH', 'F_GROUPQ', 'F_THEME4', 'F_TOTAL', 'E_UNINSUR', 'M_UNINSUR', 'EP_UNINSUR', 'MP_UNINSUR', 'E_DAYPOP', 'Shape_Length', 'Shape_Area', 'geometry']\n",
            "EPSG:4269\n"
          ]
        }
      ],
      "source": [
        "# Look at the SVI tracts now\n",
        "layer_name = \"CALIFORNIA_tract\"\n",
        "\n",
        "tracts = gpd.read_file(cdc_gdb_path, layer=layer_name)\n",
        "\n",
        "# Also contains geometry\n",
        "print(tracts.head())\n",
        "print(tracts.columns.tolist())\n",
        "print(tracts.crs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3ae0012",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "             FIPS  RPL_THEMES\n",
            "4931  06073008509      0.4912\n",
            "4932  06073008510      0.4610\n",
            "4933  06073008511      0.4802\n",
            "4934  06073008512      0.1664\n",
            "4935  06073008513      0.0467\n",
            "Rows in San Diego tracts: 627\n"
          ]
        }
      ],
      "source": [
        "# Match data types and string conventions etc\n",
        "# from chat\n",
        "tracts['FIPS'] = tracts['FIPS'].astype(str).str.replace(r'\\.0$', '', regex=True)\n",
        "tracts_sd = tracts[tracts['FIPS'].str.startswith('06073')].copy()\n",
        "\n",
        "# Keep the geometry and SVI (single number) and the FIPS code\n",
        "tracts_sd = tracts_sd[['FIPS', 'RPL_THEMES', 'geometry']].copy()\n",
        "\n",
        "print(tracts_sd[['FIPS', 'RPL_THEMES']].head())\n",
        "print(\"Rows in San Diego tracts:\", len(tracts_sd))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "70eaf5ff",
      "metadata": {},
      "source": [
        "Now match between the police zones and census tracts. Suppose that we are in a space where san diego is the whole space.\n",
        "\n",
        "The set $A$ is the set of policing zones (it is made up of some smaller sets, $A_j$, corresponding to each zone in particular).\n",
        "\n",
        "The set $B$ is the set of all census tracts (also made up of sets $B_j$). \n",
        "\n",
        "$A$ and $B$ are both subsets of the whole space (san diego greater area I think, this part was from chat). We want to match the data where $A \\cap B$ i.e. where the police zones intersect with the census tracts on social vulnerability.\n",
        "\n",
        "That is what this block of code does. There is some modification of the SVI data (suggested by chat) so that, when taking the average, it is weighted. For example, when two tracts with different SVI intersect one police zone, we take a weighted average, assigning higher weights to tracts that intersect more heavily with the police zone."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "c29cbf11",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   objectid  beat  div  serv        name         FIPS  RPL_THEMES  \\\n",
            "0         9   935    9   930  NORTH CITY  06073017029      0.0102   \n",
            "1         9   935    9   930  NORTH CITY  06073017106      0.1011   \n",
            "2         9   935    9   930  NORTH CITY  06073017304      0.3095   \n",
            "3         9   935    9   930  NORTH CITY  06073017306      0.0422   \n",
            "4         9   935    9   930  NORTH CITY  06073008324      0.0189   \n",
            "\n",
            "                                            geometry  overlap_area  \\\n",
            "0  MULTIPOLYGON Z (((479103.087 3649461.789 0, 47...  2.490648e+06   \n",
            "1  MULTIPOLYGON Z (((478835.266 3649610.423 0, 47...  1.821234e+04   \n",
            "2  POLYGON Z ((476337.773 3649093.502 0, 476337.4...  5.891610e+04   \n",
            "3  MULTIPOLYGON Z (((477697.717 3649731.986 0, 47...  6.566568e+05   \n",
            "4  POLYGON Z ((476212.978 3649065.552 0, 476210.0...  2.955893e+02   \n",
            "\n",
            "   weighted_svi  \n",
            "0  25404.609253  \n",
            "1   1841.267895  \n",
            "2  18234.534197  \n",
            "3  27710.918559  \n",
            "4      5.586638  \n"
          ]
        }
      ],
      "source": [
        "# Make CRS match\n",
        "if beats.crs != tracts_sd.crs:\n",
        "    tracts_sd = tracts_sd.to_crs(beats.crs)\n",
        "\n",
        "# Project to a metric CRS for area calculations\n",
        "beats_proj = beats.to_crs(epsg=26911)      # UTM Zone 11N\n",
        "tracts_proj = tracts_sd.to_crs(epsg=26911)\n",
        "\n",
        "# Spatial intersection\n",
        "inter = gpd.overlay(beats_proj, tracts_proj, how=\"intersection\")\n",
        "\n",
        "# Area-weighted SVI\n",
        "inter[\"overlap_area\"] = inter.geometry.area\n",
        "inter[\"weighted_svi\"] = inter[\"RPL_THEMES\"] * inter[\"overlap_area\"]\n",
        "\n",
        "print(inter.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6934014b",
      "metadata": {},
      "source": [
        "Now, we actually do this weighted averaging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db101956",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   serv  svi_rpl_themes\n",
            "0     0        0.029338\n",
            "1   110        0.241848\n",
            "2   120        0.143232\n",
            "3   230        0.162551\n",
            "4   240        0.131157\n"
          ]
        }
      ],
      "source": [
        "beat_col = \"serv\"\n",
        "\n",
        "svc_svi = (\n",
        "    inter.groupby(beat_col, dropna=False)\n",
        "    .agg(\n",
        "        weighted_svi_sum=(\"weighted_svi\", \"sum\"),\n",
        "        overlap_area_sum=(\"overlap_area\", \"sum\")\n",
        "    )\n",
        "    .reset_index()\n",
        ")\n",
        "\n",
        "svc_svi[\"svi_rpl_themes\"] = svc_svi[\"weighted_svi_sum\"] / svc_svi[\"overlap_area_sum\"]\n",
        "\n",
        "svc_svi = svc_svi[[beat_col, \"svi_rpl_themes\"]]\n",
        "\n",
        "print(svc_svi.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "227ec977",
      "metadata": {},
      "source": [
        "Finally, we combine into one data set by merging with the SOPP data. It is a left join, so that all of the service area columns present in the SOPP data set are still there (in case we want to work with those?)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "9dc01507",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "         date service_area  search_conducted  svi_rpl_themes\n",
            "0  2014-01-01          110             False        0.241848\n",
            "1  2014-01-01          320             False        0.213643\n",
            "2  2014-01-01          320             False        0.213643\n",
            "3  2014-01-01          610             False        0.121181\n",
            "4  2014-01-01          930             False        0.075382\n",
            "Missing SVI rows: 11627\n"
          ]
        }
      ],
      "source": [
        "sopp = pd.read_csv(\"./data/sopp.csv\")  # or your full file path\n",
        "sopp[\"service_area\"] = sopp[\"service_area\"].astype(str)\n",
        "\n",
        "svc_svi[beat_col] = svc_svi[beat_col].astype(str)\n",
        "\n",
        "sopp_final = sopp.merge(\n",
        "    svc_svi,\n",
        "    left_on=\"service_area\",\n",
        "    right_on=beat_col,\n",
        "    how=\"left\"\n",
        ")\n",
        "\n",
        "print(sopp_final[[\"date\", \"service_area\", \"search_conducted\", \"svi_rpl_themes\"]].head())\n",
        "print(\"Missing SVI rows:\", sopp_final[\"svi_rpl_themes\"].isna().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "babdc72c",
      "metadata": {},
      "outputs": [],
      "source": [
        "sopp_final.to_csv('./data/sopp_svi_merged.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f949d1a",
      "metadata": {},
      "source": [
        "Sanity checks on the resulting data set (from chat). The next couple of chunks all do this so that I don't have to scroll when reading it all."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "43235e2a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape: (383027, 23)\n",
            "\n",
            "Columns:\n",
            "['raw_row_number', 'date', 'time', 'service_area', 'subject_age', 'subject_race', 'subject_sex', 'type', 'arrest_made', 'citation_issued', 'warning_issued', 'outcome', 'contraband_found', 'search_conducted', 'search_person', 'search_vehicle', 'search_basis', 'reason_for_search', 'reason_for_stop', 'raw_action_taken', 'raw_subject_race_description', 'serv', 'svi_rpl_themes']\n",
            "\n",
            "\n",
            "=== SVI missingness ===\n",
            "svi_rpl_themes\n",
            "False    371400\n",
            "True      11627\n",
            "Name: count, dtype: int64\n",
            "Missing SVI proportion: 0.030355562401606154\n"
          ]
        }
      ],
      "source": [
        "df = sopp_final.copy()\n",
        "\n",
        "print(\"Shape:\", df.shape)\n",
        "print(\"\\nColumns:\")\n",
        "print(df.columns.tolist())\n",
        "print()\n",
        "\n",
        "# Missing data\n",
        "print(\"\\n=== SVI missingness ===\")\n",
        "print(df[\"svi_rpl_themes\"].isna().value_counts(dropna=False))\n",
        "print(\"Missing SVI proportion:\", df[\"svi_rpl_themes\"].isna().mean())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d875c5b0",
      "metadata": {},
      "source": [
        "The above tells us that most of the data is there and it looks like the join was (relatively) successful. The small amount of missing data (I think) makes sense since some of the police zones were weird anyway"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "588ce4d0",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== SVI range check ===\n",
            "count    371400.000000\n",
            "mean          0.346642\n",
            "std           0.232837\n",
            "min           0.075382\n",
            "25%           0.143232\n",
            "50%           0.241848\n",
            "75%           0.549244\n",
            "max           0.849382\n",
            "Name: svi_rpl_themes, dtype: float64\n",
            "Rows with SVI outside [0,1]: 0\n",
            "\n",
            "=== Within-service_area SVI consistency ===\n",
            "n_unique_svi\n",
            "0     6\n",
            "1    19\n",
            "Name: count, dtype: int64\n",
            "Service areas with >1 SVI value: 0\n",
            "\n",
            "=== Merge coverage by service_area ===\n",
            "   service_area  prop_missing_svi\n",
            "24      Unknown               1.0\n",
            "2           130               1.0\n",
            "23       County               1.0\n",
            "22     Bulletin               1.0\n",
            "20          840               1.0\n",
            "14          630               1.0\n",
            "13          620               0.0\n",
            "21          930               0.0\n",
            "19          830               0.0\n",
            "18          820               0.0\n"
          ]
        }
      ],
      "source": [
        "# SVI ranges (since chat did weighted averaging)\n",
        "print(\"\\n=== SVI range check ===\")\n",
        "print(df[\"svi_rpl_themes\"].describe())\n",
        "\n",
        "bad_range = df[(df[\"svi_rpl_themes\"] < 0) | (df[\"svi_rpl_themes\"] > 1)]\n",
        "print(\"Rows with SVI outside [0,1]:\", len(bad_range))\n",
        "if len(bad_range) > 0:\n",
        "    print(bad_range[[\"service_area\", \"svi_rpl_themes\"]].head())\n",
        "\n",
        "# Checking that SVI is consistent \n",
        "print(\"\\n=== Within-service_area SVI consistency ===\")\n",
        "\n",
        "svc_check = (\n",
        "    df.groupby(\"service_area\")[\"svi_rpl_themes\"]\n",
        "      .nunique(dropna=True)\n",
        "      .reset_index(name=\"n_unique_svi\")\n",
        ")\n",
        "\n",
        "print(svc_check[\"n_unique_svi\"].value_counts().sort_index())\n",
        "\n",
        "bad_services = svc_check[svc_check[\"n_unique_svi\"] > 1]\n",
        "print(\"Service areas with >1 SVI value:\", len(bad_services))\n",
        "if len(bad_services) > 0:\n",
        "    print(bad_services.head())\n",
        "\n",
        "print(\"\\n=== Merge coverage by service_area ===\")\n",
        "\n",
        "svc_missing = (\n",
        "    df.groupby(\"service_area\")[\"svi_rpl_themes\"]\n",
        "      .apply(lambda x: x.isna().mean())\n",
        "      .reset_index(name=\"prop_missing_svi\")\n",
        "      .sort_values(\"prop_missing_svi\", ascending=False)\n",
        ")\n",
        "\n",
        "print(svc_missing.head(10))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "23befb94",
      "metadata": {},
      "source": [
        "It seems like most police zones have a unique SVI. As you can see, some were messed up (Bulletin County is probably a full county name that somehow got separated, it seems like a pain in the ass to fix manually, so it's probably fine).\n",
        "\n",
        "Also, all of the SVI's are in the correct interval, $[0, 1]$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "9c6c438b",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Key variable missingness ===\n",
            "subject_age         0.031233\n",
            "svi_rpl_themes      0.030356\n",
            "subject_race        0.003222\n",
            "subject_sex         0.001726\n",
            "reason_for_stop     0.000572\n",
            "search_conducted    0.000000\n",
            "service_area        0.000000\n",
            "dtype: float64\n",
            "\n",
            "=== search_conducted distribution ===\n",
            "search_conducted\n",
            "False    366739\n",
            "True      16288\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n=== Key variable missingness ===\")\n",
        "key_cols = [\"search_conducted\", \"subject_age\", \"subject_race\", \"subject_sex\", \"reason_for_stop\", \"service_area\", \"svi_rpl_themes\"]\n",
        "print(df[key_cols].isna().mean().sort_values(ascending=False))\n",
        "\n",
        "print(\"\\n=== search_conducted distribution ===\")\n",
        "print(df[\"search_conducted\"].value_counts(dropna=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5fd03302",
      "metadata": {},
      "source": [
        "Our regular variables of interest also seem fine."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e24295d5",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Search rate by SVI quartile ===\n",
            "  svi_quartile       n  search_rate   svi_min   svi_max\n",
            "0      Q1(low)  100062     0.028852  0.075382  0.143232\n",
            "1           Q2  106168     0.029142  0.162551  0.241848\n",
            "2           Q3   78279     0.055366  0.321448  0.549244\n",
            "3     Q4(high)   86891     0.064989  0.653392  0.849382\n"
          ]
        }
      ],
      "source": [
        "tmp = df.dropna(subset=[\"svi_rpl_themes\", \"search_conducted\"]).copy()\n",
        "\n",
        "if tmp[\"search_conducted\"].dtype == object:\n",
        "    tmp[\"search_conducted\"] = tmp[\"search_conducted\"].astype(str).str.lower().map({\n",
        "        \"true\": 1, \"false\": 0, \"1\": 1, \"0\": 0\n",
        "    })\n",
        "else:\n",
        "    tmp[\"search_conducted\"] = tmp[\"search_conducted\"].astype(int)\n",
        "\n",
        "tmp = tmp.dropna(subset=[\"search_conducted\"])\n",
        "\n",
        "tmp[\"svi_quartile\"] = pd.qcut(tmp[\"svi_rpl_themes\"], 4, labels=[\"Q1(low)\", \"Q2\", \"Q3\", \"Q4(high)\"])\n",
        "\n",
        "summary = (\n",
        "    tmp.groupby(\"svi_quartile\")\n",
        "       .agg(\n",
        "           n=(\"search_conducted\", \"size\"),\n",
        "           search_rate=(\"search_conducted\", \"mean\"),\n",
        "           svi_min=(\"svi_rpl_themes\", \"min\"),\n",
        "           svi_max=(\"svi_rpl_themes\", \"max\"),\n",
        "       )\n",
        "       .reset_index()\n",
        ")\n",
        "\n",
        "print(\"\\n=== Search rate by SVI quartile ===\")\n",
        "print(summary)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9895a660",
      "metadata": {},
      "source": [
        "This is just some intro analysis (from chat). It looks like we can see a general trend of high SVI rows having a higher search rate. (0.02 for Q1 as opposed to 0.06 for Q4)."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
